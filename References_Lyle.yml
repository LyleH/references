####DOCKER####
#WMS STAGING
ssh -A toor@hq-stage-docker01.stagealot.com
ssh -A toor@hq-stage-docker02.stagealot.com
ssh -A toor@hq-stage-docker03.stagealot.com

#DVT STAGING
ssh -A toor@hq-stage-docker06.stagealot.com

#LYLE STAGING
ssh -A toor@hq-stage-docker07.stagealot.com


https://dashboard.wms-docker6.env

#PERFORMANCE STAGING
ssh -A toor@hq-stage-docker06.stagealot.com
Password - MokotAs7

# cd /home/toor/workspace...

# cd/workspace/dev-environments/docker
docker-machine rm default
./bin/configure.py

# cd/workspace/dev-environments/docker/collections
source compose.env

# cd/workspace/dev-environments/docker/collections
docker-machine env default
eval $(docker-machine env default)
docker ps
docker-compose pull
docker-compose up

# check logs
docker -H hq-stage-docker02:4243 logs [container]

# useful commands
sudo killall -HUP mDNSResponder
docker logs -f wmsstaging_wmsapi_1
docker logs wmsstaging_wmsapi_1 2>&1 | grep "829414Ï€3"
docker-compose stop admindock
docker-compose up --force-recreate -d admin
docker-machine upgrade default

# Linux bringing up container up
source compose-custom.env
export ENV_NAME='doker06'
export WORKSPACE=$(cd ../../../ && echo $PWD)
export COMPOSE_FILE=docker-compose.yml:dev.yml
which docker-machine &>/dev/null && eval $(docker-machine env default)

#debugging container
docker inspect <id|name>

#Installing docker-compose (linux, it is installed bt default on MAC and Windows)
$ curl -L https://github.com/docker/machine/releases/download/v0.8.2/docker-machine-`uname -s`-`uname -m` >/usr/local/bin/docker-machine && \
  chmod +x /usr/local/bin/docker-machine
sudo apt-get install python-pip
sudo pip install docker-compose
####DOCKER####

####GIT WORKFLOW####
#make new branchno 
git checkout -b makebranchname
# make your changes and commit to local branch
git add
git commit
# push to your remote branch
git push --set-upstream origin lyle_update_readme
git push
# view differences between your branch and master
git diff origin/ETL-2411..origin/master
# pull master into your branch
git status
git branch --set-upstream-to=origin/master wms-931
git status
# remove all unstaged changes
git checkout -- .
git status
git rebase -i HEAD~3
git status
git push origin HEAD:wms-931 -f
git push origin HEAD:master
# delete a local git branch using:
git branch -d branch_name
# delete a remote branch using:
git push origin --delete <branchName>
####GIT WORKFLOW####

####MySQL####seller_orders_data.py
ssh toor@hq-mysql01-nightly.stagealot.com
mysql -h db.mysql.env -u take2_bespoke catalogue -p

host: 10.4.1.31
user: take2_bespoke
database: take2
password: t4k32_b3sp0k3
port: 3306

Password - MokotAs7
mysql> delete from productlines where idproductline = 34181661;
mysql> select * from productlines where idproductline = 34181661;
####MySQL####

####MongoDB####
ssh toor@hq-mongo01-nightly.stagealot.com
ssh -A toor@hq-mongo01.stagealot.com
ping 10.4.1.31
netstat -nr
sudo route add default gw 10.0.12.1
####MongoDB####

####BUST CATALOGUE CACHE####
Curl_command (is_liquor flag, bust catalogue cache)
toor@taljenkins01:/var/log/supervisor$ curl http:# taljenkins01.stagealot.com:8000/rest/productlines/40365199 | python -m json.tool | grep is_liquor
toor@taljenkins01:/var/log/supervisor$ curl http:# taljenkins01.stagealot.com:8000/rest/cache-invalidate/varnish/productline/40365199/productline

curl http:# taljenkins01.stagealot.com:8000/rest/productlines/40400533 | python -m json.tool | grep is_liquor
curl http:# taljenkins01.stagealot.com:8000/rest/cache-invalidate/varnish/productline/40400533/productline
curl -X POST http:# wmsapi02:8010/outbound/product/{productId}
####BUST CATALOGUE CACHE####

####NGINX####
sudo ls nginx/
toor@www:/var/log$ sudo tail nginx/access.log
sudo tail nginx/php.errors.log
####NGINX####

####ORDER FULFILLMENT MANUALLY####
(venv) toor@wmsapi:/usr/local/tal/tal/tal/services/orders/bin$ export PYTHONPATH=/usr/local/tal/tal
(venv) toor@wmsapi:/usr/local/tal/tal/tal/services/orders/bin$ source /usr/local/tal/tal/venv/bin/activate
(venv) toor@wmsapi:/usr/local/tal/tal/tal/services/orders/bin$ export ROLE=DEV
# add idorder to file
(venv) toor@wmsapi:/usr/local/tal/tal/tal/services/orders/bin$ vi orders.csv
python fulfill_orders_from_csv.py orders.csv
####ORDER FULFILLMENT MANUALLY####

####KAFKA####
cat /etc/supervisor/conf.d/services.wms.conf
toor@wmsapi:/usr/local/tal/tal$ pip freeze | grep kakfa
pip install -r requirements.txt
####KAFKA####

####PRODUCTION ACCESS####
#Jumpbox
ssh -A lylehenkeman@jump-box.takealot.com

$product db
five past doctor take
mysql -h 10.2.17.240 -u tal-ro -p take2

#Admin
 curl -v --user 'Lyle.Henkeman:antiqueclient90' "https:// admin.takealot.com/s3cret/admin/index.php"

####PRODUCTION ACCESS####

####LEAVE PORTAL####
https:// esscloud.sagevip.co.za/AXIOMATIC/
Lyle.Henkeman
Takealot!
####LEAVE PORTAL####

####RABBIT MQ####
URL:taljenkins01.stagealot.com:15672
user: wms
password: wms
sudo -i
sudo rabbitmq status
rabbitmqctl stop_app
sudo rabbitmqctl start_app
ps waux | grep rabbit
ps -ef | grep rabbit
ps waux | grep rabbit
rabbitmqctl list_queues
watch -n1 rabbitmqctl list_queues
watch -n0.5 rabbitmqctl list_queues
watch -n1 rabbitmqctl list_queues -p wms
# rabbit UI
http:# localhost:15672/
####RABBIT MQ####

####TEST SICK MESSAGES INTEGRATION####
cd /usr/local/tal/s4f-wms-sick-service/bin
history
ifconfig
cd /usr/local/tal/s4f-wms-sick-service/bin
ls
python test_public_http_endpoint.py
source virtualenvs/bin/activate
python test_public_http_endpoint.py

http:# 10.0.15.222:5332/public/v-0-1-21/wms-sick/errors
####TEST SICK MESSAGES INTEGRATION####

####TEST LOGIN####
user_name: dev+1@take2.co.za
password:  test
####TEST LOGIN####

####VAGRANT ENVIRONMENTS####
Front_end
http:# www.wms.env/
Back_end
https:# admin.wms.env/s3cret/admin/index.php
User Lyle.Heneman updated with password antiqueclient90

Authorization
https:# admin.wms.env/s3cret/admin/users/index.php
Dashboard
http:# tal.wms.env:8080/
Seller_portal
http:# tal.wms.env:8822/seller_select

Stagealot
Front_end
http:# www.stagealot.env/
Back_end
https:# admin.stagealot.env/s3cret/admin
Authorization
https:# admin.stagealot.env/s3cret/admin/users/index.php
Dashboard
https:# dashboard.stagealot.env

ssh -A wms@10.0.14.4
Password - MokotAs7

ssh -A toor@dashboard.stagealot.env
ssh -A toor@taljenkins01.stagealot.com

virtualenv --python /usr/local/src/python-2.7.9/bin/python  venv

# Increase size of guest VirtualBox guest
sudo VBoxManage modifyhd /Users/lyle/VirtualBox\ VMs/WMS_Linux/WMS_Linux.vdi --resize 40000
pip install requirements.txt -e .
toor@consumer-app:/usr/local/tal/consumer_app$ virtualenv --python /usr/local/src/python-2.7.9/bin/python  venv
. venv/bin/activate
pip install -e .
export ROLE=DEV
consumer_app
cd etc/supervisor
vi service.conf
cd /etc/supervisor/conf.d/
sudo ln -s /usr/local/tal/consumer_app/etc/supervisor/service.conf consumer_app.conf
vi consumer_app.conf

toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ mv virtualenvs/ virtualenvs.for-python-2.7.3
toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ virtualenv -p /usr/local/src/python2.7.9/bin/python virtualenvs
toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ . virtualenvs/bin/activate
(virtualenvs) toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ python --version
Python 2.7.9

toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ pip install -e .
Obtaining file:# /workspace/s4f-wms-sick-service

move cd /etc /supervisor to conf.d
deactivate and reactivate vm
sudo apt-get install libffi-dev

toor@s4f-services:/usr/local/tal/s4f-wms-sick-service/virtualenvs$ cd ..
toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ ls
AUTHORS.md  HISTORY.md  README.md  bin  etc  scripts  setup.py  tests  virtualenvs  wms_sick_service  wms_sick_service.egg-info
toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ . virtualenvs/bin/activate
(virtualenvs) toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ . virtualenvs/bin/activate^C
(virtualenvs) toor@s4f-services:/usr/local/tal/s4f-wms-sick-service$ generate_proto
Compiling protobufs in:
/workspace/s4f-protocol-buffers
####VAGRANT ENVIRONMENTS####

####PYTHON UNIT TESTS VAGRANT####
Run_python_unit_tests
python -m unittest test_module.TestClass.test_method
####PYTHON UNIT TESTS VAGRANT####

####ADMIN USER_ROLE HACK DEV####
#To make your USER_ROLE work 
cd /workspace/tal_backend/docroot/s3cret/admin/vieworder.php
on line 2037 change 

if (\tal\model\UserRole::isUserInRole($loggedin, \tal\model\UserRole::ROLE_AUTH_ADMINSTRATOR)) { ?>
to
if (1==1) { ?>

and in 

cd /workspace/tal_backend/docroot/s3cret/admin/auth.php
on line 20 change

if (!\tal\model\UserRole::isUserInRole($loggedin, \tal\model\UserRole::ROLE_AUTH_ADMINSTRATOR)) {
to
if (1!=1) {
####ADMIN USER_ROLE HACK DEV####

####SERVER SPECS####
#specs
sudo lshw -short
#linux version
lsb_release -a

#amount of lines in file
wc -l file
####SERVER SPECS****

####JAVA####
#Intall JAVA on Ubuntu
 wget --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u5-b13/jdk-8u5-linux-x64.tar.gz
#follow wiki
https://www.digitalocean.com/community/tutorials/how-to-manually-install-oracle-java-on-a-debian-or-ubuntu-vps
vim ~/.bash_profile
export JAVA_HOME=$(/usr/libexec/java_home)
source ~/.bash_profile
echo $JAVA_HOME
####JAVA####

####JENKINS####
#building a new docker image
http://hq-docker01:8080/
#nacigate and click on the service / image in question
#click build with parameters
# in 'repository' add the repo you want for example: s4f-seller-message-service. see the following error:
# ERROR: Error: image takealot/s4f-seller-message-service:latest not found

####zshrc####
~/.zshrc
####zshrc####

####BREW####
brew cask uninstall virtualbox
brew cask install virtualbox
brew install docker
brew install boot2docker
boot2docker init
boot2docker up

####Pipe Linux#####
#The standard output stream will be copied to the file, it will still be visible in the terminal. If the file already exists, it gets overwritten.
command | tee output.txt

####JVM####
##   Environment variables:
VM_ARGS - optional java args, e.g. -Dprop=val

JVM_ARGS="-Xms512m -Xmx512m" jmeter.sh etc.
####JVM####

####KAFKA#####
docker build -t tal_kafka_rest_proxy:latest .
####KAFKA#####

####LOGFIRE####
PP
Host: b1ppsftp.logfireapps.com
User: takealot_pp_if
Pass: 2Frdd8vU
Port: 22
 
UAT
Host: uatsftp.logfireapps.com
User: takealot_uat_if
Pass:  (|EP4).C
Port 22
 
User ID : takealot_if
Password: Pt8e$d7W
Remote Host: b1sftp.logfireapps.com
Remote Port: 22
 
Putty:
Putty UAT
 "C:\Program Files\Logfire\putty.exe" -ssh takealot_uat_rf@uat.logfireapps.com  -pw AN!&v*o)
 ####LOGFIRE####